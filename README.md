# ğŸ’Œ Traductor del Amor

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![React](https://img.shields.io/badge/react-18.2+-61DAFB.svg)
![Status](https://img.shields.io/badge/status-MVP-orange.svg)

**Interpreta mensajes ambiguos de pareja usando IA Â· Entrena respuestas asertivas Â· Construido 100% gratis**

[Demo en Vivo](https://traductor-amor.vercel.app) Â· [DocumentaciÃ³n](#-cÃ³mo-funciona) Â· [Reportar Bug](https://github.com/tu-usuario/traductor-amor/issues)

</div>

---

## ğŸ¯ Â¿QuÃ© es esto?

Â¿Has recibido un **"Solo quiero fluir"** y no sabÃ­as si era evasiÃ³n de compromiso o simplemente relajaciÃ³n? 

**Traductor del Amor** es un sistema de IA que interpreta el **significado emocional real** detrÃ¡s de mensajes ambiguos en relaciones de pareja, usando psicologÃ­a basada en evidencia (Gottman, Sue Johnson) + RAG + LLMs.

### ğŸ’¡ **Diferenciador clave**

No es solo un chatbot. Es un **entrenador de comunicaciÃ³n** que:

âœ… **Traduce** mensajes ambiguos a su significado psicolÃ³gico  
âœ… **Detecta** seÃ±ales de manipulaciÃ³n, evasiÃ³n, bajo compromiso  
âœ… **EvalÃºa** tus respuestas propuestas (scoring 0-100%)  
âœ… **Sugiere** mejoras basadas en literatura de psicologÃ­a de pareja  

---

## ğŸš€ Demo RÃ¡pida

### Ejemplo 1: TraducciÃ³n BÃ¡sica

**Input:**
```
"Solo quiero fluir y ver quÃ© pasa"
```

**Output:**
```json
{
  "significado": "Baja implicaciÃ³n emocional, evasiÃ³n de compromiso explÃ­cito",
  "seÃ±ales": ["evasiÃ³n", "ambigÃ¼edad intencional", "pasividad"],
  "nivel_alerta": "MEDIO",
  "recomendaciÃ³n": "Mantener lÃ­mites claros. No invertir energÃ­a emocional excesiva sin reciprocidad."
}
```

---

### Ejemplo 2: Scoring de Respuesta

**Mensaje original:**
```
"Solo quiero fluir"
```

**Tu respuesta propuesta:**
```
"Vale, hablamos luego"
```

**EvaluaciÃ³n:**
```json
{
  "probabilidad_exito": 45,
  "analisis": "Respuesta demasiado pasiva. No establece lÃ­mites ni expresa necesidades propias.",
  "fortalezas": ["no reactiva", "neutral"],
  "mejoras": ["falta claridad de expectativas", "no comunica necesidades"],
  "sugerencia": "Considera: 'Entiendo que quieres relajarte. Yo necesito claridad sobre quÃ© buscas en esta relaciÃ³n. Â¿Podemos hablarlo?'"
}
```

---

## âœ¨ Features

### Core Features (MVP)

| Feature | DescripciÃ³n | Status |
|---------|-------------|--------|
| **TraducciÃ³n Emocional** | Interpreta significado real de mensajes ambiguos | âœ… Live |
| **DetecciÃ³n de SeÃ±ales** | Identifica manipulaciÃ³n, evasiÃ³n, gaslighting | âœ… Live |
| **Scoring de Respuestas** | EvalÃºa tus respuestas propuestas (0-100%) | âœ… Live |
| **DetecciÃ³n de Sarcasmo** | Ajusta interpretaciÃ³n si detecta sarcasmo | âœ… Live |
| **AnÃ¡lisis de Sentimiento** | Complementa contexto emocional | âœ… Live |

### Optimizaciones Backend

| OptimizaciÃ³n | Impacto | Status |
|--------------|---------|--------|
| **Cache LRU** | 50% latencia en mensajes comunes | âœ… Implementado |
| **Rate Limiting Dual** | ProtecciÃ³n IP + global | âœ… Implementado |
| **ValidaciÃ³n Input** | Previene inputs maliciosos | âœ… Implementado |
| **Timeout Management** | No mÃ¡s requests colgados | âœ… Implementado |
| **Logging & MÃ©tricas** | Observabilidad bÃ¡sica | âœ… Implementado |

---

## ğŸ› ï¸ Tech Stack

### **Frontend**
- **Framework:** React 18 + Vite
- **Styling:** TailwindCSS
- **Estado:** useState + Context API + localStorage
- **Hosting:** Vercel (deploy automÃ¡tico)

### **Backend**
- **Framework:** FastAPI (Python 3.10+)
- **LLM:** Groq API (Mixtral-8x7B) - 14k req/dÃ­a gratis
- **Vector DB:** FAISS (indexaciÃ³n local)
- **Embeddings:** sentence-transformers (multilingual)
- **Detectores:** DistilBERT (sarcasmo), RoBERTa (sentimiento)
- **Cache:** LRU Cache (memoria, 128 entradas)
- **Rate Limiting:** SlowAPI + custom global limiter
- **Hosting:** Render Free Tier

### **Stack 100% Gratuito**

| Componente | TecnologÃ­a | Coste/mes |
|------------|-----------|-----------|
| Frontend | Vercel | â‚¬0 |
| Backend | Render Free | â‚¬0 |
| LLM | Groq API | â‚¬0 |
| Vector DB | FAISS (local) | â‚¬0 |
| Detectores | Hugging Face | â‚¬0 |
| **TOTAL** | - | **â‚¬0** |

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 USUARIO (Navegador)                     â”‚
â”‚              localStorage: Cache local                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            FRONTEND (React + Tailwind)                  â”‚
â”‚            Vercel Â· traductor-amor.vercel.app           â”‚
â”‚                                                          â”‚
â”‚  âœ… Detecta cold start y muestra aviso                 â”‚
â”‚  âœ… Maneja errores con mensajes claros                 â”‚
â”‚  âœ… Guarda resultados en localStorage                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTPS
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          BACKEND API (FastAPI) - OPTIMIZADO            â”‚
â”‚          Render Free Â· api-traductor.onrender.com      â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  CACHE LRU (128 entradas)              â”‚            â”‚
â”‚  â”‚  Hit rate: 40-60%                      â”‚            â”‚
â”‚  â”‚  Latencia con cache: 0.5s âš¡           â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  RATE LIMITING                          â”‚            â”‚
â”‚  â”‚  Â· Por IP: 10 req/min                  â”‚            â”‚
â”‚  â”‚  Â· Global: 600 req/hora                â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  PIPELINE PROCESAMIENTO                â”‚            â”‚
â”‚  â”‚  1. ValidaciÃ³n input (1-512 tokens)   â”‚            â”‚
â”‚  â”‚  2. Detectores (sarcasmo, sentimiento) â”‚            â”‚
â”‚  â”‚  3. RAG Engine (FAISS search)          â”‚            â”‚
â”‚  â”‚  4. Groq API (Mixtral-8x7B)            â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LLM EXTERNO (Groq API) âš¡                      â”‚
â”‚                                                          â”‚
â”‚  Â· Modelo: Mixtral-8x7B-32768                          â”‚
â”‚  Â· Latencia: 1-2s                                       â”‚
â”‚  Â· LÃ­mite: 14,400 req/dÃ­a (gratis)                     â”‚
â”‚  Â· Timeout: 10s mÃ¡ximo                                  â”‚
â”‚  Â· Retry: 1 intento con backoff                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LATENCIA TOTAL:
Â· Con cache hit: 0.5s âš¡âš¡
Â· Sin cache: 2-5s âš¡
Â· Cold start: 30-60s (aviso en UI)
```

---

## âš¡ Performance

| MÃ©trica | Valor | Notas |
|---------|-------|-------|
| **Latencia promedio** | 0.5-5s | Con cache: 0.5s, Sin cache: 2-5s |
| **Cache hit rate** | 40-60% | Para mensajes comunes |
| **Requests/hora** | ~900 | 600 efectivos + cache hits |
| **Usuarios concurrentes** | 100+ | Gracias a Groq API |
| **Rate limit por IP** | 10/min | Previene spam |
| **Rate limit global** | 600/hora | ProtecciÃ³n anti-abuso |
| **Uptime** | 99%+ | Groq API muy estable |

---

## ğŸš¦ Quick Start

### Requisitos Previos

- Python 3.10+
- Node.js 18+
- Cuenta Groq (gratis): https://console.groq.com

### InstalaciÃ³n Local

#### 1. Clonar repositorio
```bash
git clone https://github.com/tu-usuario/traductor-amor.git
cd traductor-amor
```

#### 2. Setup Backend
```bash
cd backend
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env
# Editar .env y aÃ±adir tu GROQ_API_KEY
```

**requirements.txt:**
```txt
fastapi==0.104.1
uvicorn==0.24.0
groq==0.4.1
sentence-transformers==2.2.2
faiss-cpu==1.7.4
transformers==4.35.0
torch==2.1.0
slowapi==0.1.9
cachetools==5.3.0
psutil==5.9.0
pydantic==2.5.0
```

#### 3. Descargar modelos (primera vez)
```bash
python -m app.services.download_models
```

#### 4. Ejecutar backend
```bash
uvicorn app.main:app --reload --port 8000
```

#### 5. Setup Frontend
```bash
cd ../frontend
npm install

# Configurar API URL
echo "VITE_API_URL=http://localhost:8000" > .env.local
```

#### 6. Ejecutar frontend
```bash
npm run dev
```

#### 7. Abrir en navegador
```
http://localhost:5173
```

---

## ğŸ“– Uso

### API Endpoints

#### 1. Health Check
```bash
GET /health
```

**Respuesta:**
```json
{
  "status": "awake",
  "uptime_seconds": 300.5,
  "metrics": {
    "cache": {
      "cache_hits": 45,
      "cache_misses": 55,
      "hit_rate_percent": 45.0,
      "cache_size": 42,
      "max_size": 128
    },
    "rate_limiting": {
      "requests_last_hour": 87,
      "limit": 600,
      "remaining": 513
    }
  }
}
```

#### 2. Traducir Mensaje
```bash
POST /traducir
Content-Type: application/json

{
  "mensaje": "Solo quiero fluir"
}
```

**Respuesta:**
```json
{
  "significado": "Baja implicaciÃ³n emocional, evasiÃ³n de compromiso",
  "senales": ["evasiÃ³n", "ambigÃ¼edad", "pasividad"],
  "nivel_alerta": "MEDIO",
  "recomendacion": "Mantener lÃ­mites claros...",
  "metadata": {
    "latency_seconds": 2.3,
    "from_cache": false,
    "sarcasmo_detected": false,
    "sentimiento": {
      "label": "neutral",
      "score": 0.62
    }
  }
}
```

#### 3. Evaluar Respuesta
```bash
POST /evaluar_respuesta
Content-Type: application/json

{
  "mensaje_original": "Solo quiero fluir",
  "respuesta_propuesta": "Vale, hablamos luego"
}
```

**Respuesta:**
```json
{
  "probabilidad_exito": 45,
  "analisis": "Respuesta demasiado pasiva...",
  "fortalezas": ["no reactiva", "neutral"],
  "mejoras": ["falta claridad", "no expresa necesidades"],
  "sugerencia": "Considera: 'Entiendo que quieres relajarte...'",
  "metadata": {
    "latency_seconds": 3.1,
    "from_cache": true
  }
}
```

---

## ğŸ”’ Rate Limiting

### LÃ­mites por IP
- **10 requests/minuto** por endpoint
- Respuesta 429 con `retry_after` si se excede

### LÃ­mite Global
- **600 requests/hora** para toda la aplicaciÃ³n
- Protege contra abuso masivo
- Respuesta 503 si se excede

### Ejemplo de Error
```json
{
  "error": "rate_limit_exceeded",
  "message": "Has excedido el lÃ­mite de requests. Espera un momento.",
  "retry_after": 60
}
```

---

## ğŸ§ª Testing

### Tests Unitarios
```bash
cd backend
python -m pytest tests/
```

### Tests de IntegraciÃ³n
```bash
python -m pytest tests/integration/
```

### Test Manual de Cache
```bash
# Primer request (cache miss)
curl -X POST http://localhost:8000/traducir \
  -H "Content-Type: application/json" \
  -d '{"mensaje": "Solo quiero fluir"}' \
  -w "\nTime: %{time_total}s\n"

# Segundo request (cache hit, deberÃ­a ser <1s)
curl -X POST http://localhost:8000/traducir \
  -H "Content-Type: application/json" \
  -d '{"mensaje": "Solo quiero fluir"}' \
  -w "\nTime: %{time_total}s\n"
```

---

## ğŸš€ Deployment

### Deploy Backend en Render

1. **Crear cuenta** en [Render.com](https://render.com)

2. **Conectar GitHub** al repositorio

3. **Crear Web Service:**
   - Tipo: Python 3
   - Build: `pip install -r requirements.txt && python -m app.services.download_models`
   - Start: `uvicorn app.main:app --host 0.0.0.0 --port 10000`
   - Plan: **Free**

4. **Variables de entorno:**
```env
GROQ_API_KEY=tu_api_key_aqui
MAX_TOKENS=512
TEMPERATURE=0.3
RATE_LIMIT_PER_MINUTE=10
RATE_LIMIT_GLOBAL_HOUR=600
CACHE_MAX_SIZE=128
LOG_LEVEL=INFO
```

5. **Deploy automÃ¡tico** âœ…

### Deploy Frontend en Vercel

1. **Crear cuenta** en [Vercel.com](https://vercel.com)

2. **Import proyecto** desde GitHub

3. **Configurar:**
   - Framework: React
   - Build: `npm run build`
   - Output: `dist/`
   - Variables entorno:
```env
VITE_API_URL=https://traductor-amor-api.onrender.com
```

4. **Deploy automÃ¡tico** âœ…

---

## ğŸ“Š MÃ©tricas a Observar (Primeros 7 dÃ­as)

### AdopciÃ³n
- [ ] Usuarios Ãºnicos
- [ ] Requests totales
- [ ] Rate de retorno (>20% = buena seÃ±al)

### Performance
- [ ] Cache hit rate real (target: >40%)
- [ ] Latencia promedio (target: <3s)
- [ ] Rate de errores (target: <5%)

### Feedback Cualitativo
- [ ] Â¿La interpretaciÃ³n es Ãºtil?
- [ ] Â¿El scoring tiene sentido?
- [ ] Â¿La UX es clara?

---

## ğŸ—ºï¸ Roadmap

### âœ… Fase 1: MVP (Actual)
- [x] TraducciÃ³n de mensajes
- [x] Scoring de respuestas
- [x] DetecciÃ³n sarcasmo
- [x] Cache LRU
- [x] Rate limiting dual
- [x] Deploy gratuito

### ğŸ”„ Fase 2: Mejoras (En progreso)
- [ ] Historial de conversaciones (localStorage)
- [ ] Ejemplos pre-cargados
- [ ] Modo comparaciÃ³n de respuestas
- [ ] Exportar anÃ¡lisis a PDF
- [ ] Compartir resultados (social)

### ğŸ”® Fase 3: Escalar (Futuro)
- [ ] Historial persistente (PostgreSQL)
- [ ] Dashboard de progreso usuario
- [ ] API pÃºblica con autenticaciÃ³n
- [ ] Modelo fine-tuned especÃ­fico
- [ ] Mobile app (React Native)

---

## ğŸ¤ Contributing

### Â¿CÃ³mo contribuir?

1. **Fork** el repositorio
2. **Crea** una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. **Push** a la rama (`git push origin feature/AmazingFeature`)
5. **Abre** un Pull Request

### Ãreas donde se necesita ayuda

- ğŸ§  **PsicologÃ­a:** Mejorar interpretaciones y prompts
- ğŸ¨ **UI/UX:** Mejorar diseÃ±o y experiencia usuario
- ğŸ”¬ **Testing:** AÃ±adir mÃ¡s tests y edge cases
- ğŸ“š **DocumentaciÃ³n:** TraducciÃ³n a inglÃ©s, tutoriales
- ğŸ¤– **ML:** Mejorar detectores de sarcasmo/sentimiento

---

## ğŸ“ Limitaciones Conocidas

### TÃ©cnicas
- âš ï¸ **Cold start:** 30-60s tras 15min inactividad (Render free tier)
- âš ï¸ **Latencia:** 2-5s sin cache (mejora con uso frecuente)
- âš ï¸ **Rate limits:** 600 req/hora total
- âš ï¸ **No persistencia:** Historial solo en sesiÃ³n actual

### De Producto
- âš ï¸ **No reemplaza terapia:** Es una herramienta complementaria
- âš ï¸ **PrecisiÃ³n limitada:** ~75% de precisiÃ³n en interpretaciones
- âš ï¸ **Sesgo cultural:** Entrenado principalmente en literatura occidental
- âš ï¸ **Idioma:** Solo espaÃ±ol por ahora

---

## ğŸ” Privacidad & Seguridad

âœ… **No se guardan datos personales**  
âœ… **No se almacenan mensajes entre sesiones**  
âœ… **API calls a Groq son efÃ­meras**  
âœ… **Rate limiting previene spam**  
âœ… **ValidaciÃ³n y sanitizaciÃ³n de inputs**  

âš ï¸ **Importante:** No uses datos sensibles o identificables. Es una demo pÃºblica.

---

## ğŸ“„ License

Este proyecto estÃ¡ bajo licencia MIT - ver [LICENSE](LICENSE) para detalles.

---

## ğŸ‘¤ Autor

**Tu Nombre**

- LinkedIn: [tu-perfil](https://linkedin.com/in/tu-perfil)
- GitHub: [@tu-usuario](https://github.com/tu-usuario)
- Email: tu-email@ejemplo.com

---

## ğŸ™ Agradecimientos

- **Groq** por API LLM gratuita y sÃºper rÃ¡pida
- **Render & Vercel** por hosting gratuito
- **Hugging Face** por modelos open-source
- **John Gottman** y **Sue Johnson** por su investigaciÃ³n en psicologÃ­a de pareja
- Comunidad de IA y desarrolladores open-source

---

## ğŸ“š Referencias

### PsicologÃ­a de Pareja
- Gottman, J. (1999). *The Seven Principles for Making Marriage Work*
- Johnson, S. (2008). *Hold Me Tight: Seven Conversations for a Lifetime of Love*
- Perel, E. (2017). *The State of Affairs: Rethinking Infidelity*

### TÃ©cnicas
- [RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)
- [FAISS Documentation](https://github.com/facebookresearch/faiss)
- [Groq API Docs](https://console.groq.com/docs)

---

<div align="center">

**â­ Si este proyecto te parece Ãºtil, dale una estrella en GitHub â­**

**ğŸ”— [Demo en Vivo](https://traductor-amor.vercel.app) | [DocumentaciÃ³n](https://github.com/tu-usuario/traductor-amor/wiki) | [Reportar Issue](https://github.com/tu-usuario/traductor-amor/issues)**

Hecho con â¤ï¸ y mucho â˜• Â· 2024

</div>
